{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lines', 'string', 'words'], ['name', 'Jeff']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "lines = [['lines is was some string of words'], ['My name is Jeff']]\n",
    "\n",
    "\n",
    "\n",
    "def filter_nouns(data):\n",
    "    \n",
    "    i = 0\n",
    "    nouns = None\n",
    "    noun_list = []\n",
    "    while i < len(data):\n",
    "        lines = ''.join(data[i])\n",
    "        # function to test if something is a noun\n",
    "        is_noun = lambda pos: pos[:2] == 'NN'\n",
    "        # do the nlp stuff\n",
    "        tokenized = nltk.word_tokenize(lines)\n",
    "        nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
    "        noun_list = [*noun_list, nouns]\n",
    "        i += 1\n",
    "        \n",
    "    return noun_list\n",
    "    \n",
    "\n",
    "filter_nouns(lines)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cluster/spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### Problem Statement ###\n",
    "Let's say you have a square matrix which consists of cosine similarities (values between 0 and 1).\n",
    "This square matrix can be of any size. \n",
    "You want to get clusters which maximize the values between elemnts in the cluster.\n",
    "For example, for the following matrix:\n",
    "  |  A  |  B  |  C  |  D\n",
    "A | 1.0 | 0.1 | 0.6 |  0.4\n",
    "B | 0.1 | 1.0 | 0.1 |  0.2\n",
    "C | 0.6 | 0.1 | 1.0 |  0.7\n",
    "D | 0.4 | 0.2 | 0.7 |  1.0\n",
    "You should get 2 clusters:\n",
    "cluster #1: B\n",
    "cluster #2: A, C, D\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "mat = np.matrix([[1.,.1,.6,.4],[.1,1.,.1,.2],[.6,.1,1.,.7],[.4,.2,.7,1.]])\n",
    "SpectralClustering(2).fit_predict(mat)\n",
    "# >>> array([0, 1, 0, 0], dtype=int32)\n",
    "\n",
    "# i.e., A, C, D belong to Cluster \"0\"\n",
    "# whereas B belongs to Cluster \"1\"\n",
    "# The algorithm takes the top k eigenvectors of the input matrix corresponding to the largest eigenvalues, \n",
    "# then runs the k-mean algorithm on the new matrix. Here is a simple code that does this for your matrix:\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "eigen_values, eigen_vectors = np.linalg.eigh(mat)\n",
    "KMeans(n_clusters=2, init='k-means++').fit_predict(eigen_vectors[:, 2:4])\n",
    "# >>> array([0, 1, 0, 0], dtype=int32)\n",
    "\n",
    "# For the cases you want the algorithm to figure out the number of clusters by itself, \n",
    "# you can use Density Based Clustering Algorithms like DBSCAN:\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "DBSCAN(min_samples=1).fit_predict(mat)\n",
    "# >>> array([0, 1, 2, 2])\n",
    "\n",
    "# Source: http://stackoverflow.com/a/30093501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Define the documents\n",
    "import numpy as np\n",
    "# captions = filter_nouns(train_captions)\n",
    "# print(captions)\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. \\\n",
    "Though he lost the support of some republican friends, Trump is friends with President Putin\"\n",
    "\n",
    "doc_election = \"President Trump says Putin had no political interference is the election outcome. \\\n",
    "He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing \\\n",
    "to do with the election\"\n",
    "\n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as \\\n",
    "the Prime Minister earlier in his political career\"\n",
    "\n",
    "# documents = [doc_trump, doc_election, doc_putin]\n",
    "# documents = [[doc_trump], [doc_election], [doc_putin]]\n",
    "captions = [['start', 'skateboarder', 'trick', 'skateboard', 'ramp', 'end', '>'], ['start', 'person', 'air', 'skis', 'end', '>'], ['start', 'wood', 'door', 'boards', 'end', '>'], ['start', 'A', 'Do', 'Enter', 'sign', 'road', 'stadium', 'end', '>'], ['start', '>', 'Small', 'child', 'chair', 'plate', 'end', '>'], ['start', '>', 'groups', 'people', 'toilet', 'area', 'end', '>'], ['start', 'hand', 'cellphone', 'end', '>'], ['start', '>', 'People', 'computers', 'student', 'room', 'end', '>'], ['start', '>', 'birds', 'field', 'end', '>'], ['start', 'man', 'cell', 'phone', 'park', 'end', '>'], ['start', 'A', 'group', 'men', 'table', 'microphones', 'speech', 'end', '>'], ['start', 'bathroom', 'toilet', 'sprayer', 'wall', 'end', '>'], ['start', 'A', 'woman', 'bench', 'phone', 'end', '>'], ['start', 'woman', 'clock', 'purse', 'market', 'end', '>'], ['start', 'surfer', 'hand', 'signal', 'end', '>'], ['start', 'A', 'cat', 'asphalt', 'end', '>'], ['start', '>', 'carrots', 'cut', 'squash', 'carrots', 'end', '>'], ['start', '>', 'Traffic', 'lights', 'intersection', 'world', 'end', '>'], ['start', 'man', 'goatee', 'backseat', 'vehicle', 'luggage', 'end', '>'], ['start', 'A', 'street', 'sign', 'intersection', 'Beacon', 'Ave', 'Stevens', 'St.', '<', 'end', '>'], ['start', 'kid', 'skateboard', 'kid', 'end', '>'], ['start', 'A', 'apple', 'clock', 'display', 'end', '>'], ['start', 'A', 'bunch', 'color', 'watches', 'table', 'end', '>'], ['start', 'man', 'suit', 'standing', 'front', 'stove', 'end', '>'], ['start', '>', 'Pizzas', 'sauce', 'cheese', 'table', 'end', '>'], ['start', 'variety', 'vegetables', 'sticks', 'tray', 'control', 'end', '>'], ['start', 'bus', 'road', 'driver', 'end', '>'], ['start', 'A', 'pizza', 'cut', 'pieces', 'top', 'counter', 'end', '>'], ['start', 'plate', 'breakfast', 'food', 'eggs', 'toast', 'hash', 'browns', 'end', '>'], ['start', 'transit', 'bus', 'lot', 'end', '>'], ['start', 'man', 'air', 'skateboard', 'end', '>'], ['start', '>', 'ground', 'plane', 'end', '>'], ['start', 'person', 'bananas', 'back', 'end', '>'], ['start', '>', 'Three', 'zebras', 'field', 'grass', 'end', '>'], ['start', 'A', 'couple', 'pieces', 'toast', 'cup', 'syrup', 'end', '>'], ['start', '>', 'Many', 'dishes', 'people', 'end', '>'], ['start', 'herd', 'wire', 'fence', 'end', '>'], ['start', 'A', 'slice', 'pizza', 'cheese', 'crust', 'end', '>'], ['start', 'herd', 'cows', 'field', 'end', '>'], ['start', 'paper', 'plate', 'dog', 'sandwich', 'cream', 'cheese', 'end', '>'], ['start', 'baby', 'boy', 'room', 'baby', 'doll', 'end', '>'], ['start', 'man', 'woman', 'tennis', 'rackets', 'court', 'end', '>'], ['start', 'bus', 'side', 'man', 'storage', 'bus', '<', 'end', '>'], ['start', 'A', 'girl', 'man', 'tie', 'end', '>'], ['start', 'A', 'baseball', 'player', 'bat', 'game', 'end', '>'], ['start', 'man', 'ocean', 'waters', 'waves', 'end', '>'], ['start', 'A', 'couple', 'women', 'top', 'tennis', 'court', 'end', '>'], ['start', '>', 'zebra', 'end', '>'], ['start', 'clock', 'side', 'beige', 'bell', 'tower', 'end', '>'], ['start', 'bear', 'teeth', 'camera', 'end', '>'], ['start', 'A', 'remote', 'sink', 'room', 'end', '>'], ['start', 'A', 'bathroom', 'sink', 'mirror', 'toilet', 'tub', 'end', '>'], ['start', 'passenger', 'train', 'platform', 'end', '>'], ['start', 'A', 'group', 'people', 'restaurant', 'table', 'end', '>'], ['start', 'men', 'glasses', 'end', '>'], ['start', 'A', 'woman', 'slice', 'pizza', 'cheese', 'end', '>'], ['start', 'A', 'motor', 'bike', 'side', 'road', 'end', '>'], ['start', 'plate', 'foods', 'cheeses', 'end', '>'], ['start', '>', 'Donuts', 'cell', 'phone', 'table', 'end', '>'], ['start', '>', 'Six', 'plastic', 'containers', 'vegetables', 'end', '>'], ['start', 'horse', 'standing', 'front', 'portrait', 'village', 'end', '>'], ['start', 'women', 'hill', 'end', '>'], ['start', 'man', 'glasses', 'suit', 'vest', 'end', '>'], ['start', 'kitchen', 'counters', 'chrome', 'microwave', 'backsplash', 'end', '>'], ['start', 'retriever', 'dog', 'desk', 'end', '>'], ['start', 'A', 'dog', 'leash', 'reflection', 'door', 'end', '>'], ['start', 'giraffe', 'umbrella', 'end', '>'], ['start', 'skier', 'blue', 'jacket', 'goggles', 'end', '>'], ['start', 'skier', 'view', 'mountain', 'top', 'end', '>'], ['start', 'truck', 'highway', 'end', '>'], ['start', 'batter', 'plate', 'swing', 'pitch', 'end', '>'], ['start', 'train', 'towards', 'train', 'station', 'end', '>'], ['start', '>', 'People', 'baggage', 'claim', 'area', 'airport', 'end', '>'], ['start', 'bride', 'groom', 'wedding', 'cake', 'end', '>'], ['start', '>', 'Parking', 'meters', 'front', 'spaces', 'lot', 'end', '>'], ['start', 'A', 'bunch', 'road', 'signs', 'side', 'road', 'end', '>'], ['start', 'plate', 'food', 'table', 'pitchers', 'end', '>'], ['start', 'laptop', 'desk', 'coke', 'bottle', 'Apple', 'monitor', 'end', '>'], ['start', 'A', 'person', 'skis', 'lays', 'snow', 'legs', 'end', '>'], ['start', '>', 'Cars', 'street', 'traffic', 'light', 'end', '>'], ['start', '>', 'people', 'tables', 'outdoors', 'end', '>'], ['start', 'giraffe', 'boulder', 'wall', 'end', '>'], ['start', 'A', 'leather', 'chair', 'book', 'arm', 'end', '>'], ['start', 'A', 'group', 'cross', 'country', 'skiiers', 'race', 'end', '>'], ['start', 'table', 'plates', 'food', 'end', '>'], ['start', 'A', 'couple', 'animals', 'day', 'end', '>'], ['start', 'man', 'tie', 'front', 'mirror', 'end', '>'], ['start', 'cat', 'piece', 'luggage', 'end', '>'], ['start', 'elephant', 'background', 'monkey', 'sides', 'end', '>'], ['start', 'man', 'tennis', 'ball', 'end', '>'], ['start', 'A', 'bathroom', 'door', 'end', '>'], ['start', 'bar', 'blender', 'liquid', 'end', '>'], ['start', 'girafee', 'top', 'tree', 'girafee', 'end', '>'], ['start', 'A', 'clock', 'tower', 'towering', 'city', 'end', '>'], ['start', 'man', 'motor', 'cycle', 'saddle', 'bags', 'end', '>'], ['start', 'mug', 'keyboard', 'desk', 'end', '>'], ['start', 'man', 'drives', 'horse', 'carriage', 'end', '>'], ['start', '>', 'zebras', 'side', 'side', 'grass', 'end', '>'], ['start', '>', 'Inside', 'apartment', 'door', 'chairs', 'refrigerator', 'end', '>'], ['start', 'bathroom', 'beige', 'flooring', 'walls', 'end', '>']]\n",
    "print(np.size(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air</th>\n",
       "      <th>airport</th>\n",
       "      <th>animals</th>\n",
       "      <th>apartment</th>\n",
       "      <th>apple</th>\n",
       "      <th>area</th>\n",
       "      <th>arm</th>\n",
       "      <th>asphalt</th>\n",
       "      <th>ave</th>\n",
       "      <th>baby</th>\n",
       "      <th>...</th>\n",
       "      <th>waters</th>\n",
       "      <th>waves</th>\n",
       "      <th>wedding</th>\n",
       "      <th>wire</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>wood</th>\n",
       "      <th>world</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Caption 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Caption 100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             air  airport  animals  apartment  apple  area  arm  asphalt  ave  \\\n",
       "Caption 1      0        0        0          0      0     0    0        0    0   \n",
       "Caption 2      1        0        0          0      0     0    0        0    0   \n",
       "Caption 3      0        0        0          0      0     0    0        0    0   \n",
       "Caption 4      0        0        0          0      0     0    0        0    0   \n",
       "Caption 5      0        0        0          0      0     0    0        0    0   \n",
       "...          ...      ...      ...        ...    ...   ...  ...      ...  ...   \n",
       "Caption 96     0        0        0          0      0     0    0        0    0   \n",
       "Caption 97     0        0        0          0      0     0    0        0    0   \n",
       "Caption 98     0        0        0          0      0     0    0        0    0   \n",
       "Caption 99     0        0        0          1      0     0    0        0    0   \n",
       "Caption 100    0        0        0          0      0     0    0        0    0   \n",
       "\n",
       "             baby  ...  waters  waves  wedding  wire  woman  women  wood  \\\n",
       "Caption 1       0  ...       0      0        0     0      0      0     0   \n",
       "Caption 2       0  ...       0      0        0     0      0      0     0   \n",
       "Caption 3       0  ...       0      0        0     0      0      0     1   \n",
       "Caption 4       0  ...       0      0        0     0      0      0     0   \n",
       "Caption 5       0  ...       0      0        0     0      0      0     0   \n",
       "...           ...  ...     ...    ...      ...   ...    ...    ...   ...   \n",
       "Caption 96      0  ...       0      0        0     0      0      0     0   \n",
       "Caption 97      0  ...       0      0        0     0      0      0     0   \n",
       "Caption 98      0  ...       0      0        0     0      0      0     0   \n",
       "Caption 99      0  ...       0      0        0     0      0      0     0   \n",
       "Caption 100     0  ...       0      0        0     0      0      0     0   \n",
       "\n",
       "             world  zebra  zebras  \n",
       "Caption 1        0      0       0  \n",
       "Caption 2        0      0       0  \n",
       "Caption 3        0      0       0  \n",
       "Caption 4        0      0       0  \n",
       "Caption 5        0      0       0  \n",
       "...            ...    ...     ...  \n",
       "Caption 96       0      0       0  \n",
       "Caption 97       0      0       0  \n",
       "Caption 98       0      0       1  \n",
       "Caption 99       0      0       0  \n",
       "Caption 100      0      0       0  \n",
       "\n",
       "[100 rows x 252 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(captions)\n",
    "# Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def construct_matrix(document):\n",
    "    \n",
    "    # Create the Document Term Matrix\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    \n",
    "    i = 0\n",
    "    df = None\n",
    "    noun_list = []\n",
    "    while i < len(document):\n",
    "        j = 0\n",
    "        word_list = []\n",
    "        while j < len(document[i]):\n",
    "            if document[i][j] == 'start':\n",
    "                document[i].remove(document[i][j])\n",
    "            if document[i][j] == 'end':\n",
    "                document[i].remove(document[i][j])\n",
    "            if document[i][j] == '>':\n",
    "                document[i].remove(document[i][j])            \n",
    "            j += 1\n",
    "        \n",
    "        noun_str = ' '.join(document[i])\n",
    "\n",
    "        noun_list = [*noun_list, noun_str]\n",
    "        i += 1\n",
    "\n",
    "    sparse_matrix = count_vectorizer.fit_transform(noun_list)\n",
    "\n",
    "    # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    \n",
    "    count = 0\n",
    "    numbers = []\n",
    "    while count < 100:\n",
    "        count += 1\n",
    "        numbers = [*numbers, \"Caption {}\".format(len(numbers) + 1)]\n",
    "    \n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=[x for x in numbers]) \n",
    "\n",
    "    return df\n",
    "\n",
    "construct_matrix(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is a sentence']\n"
     ]
    }
   ],
   "source": [
    "# sentence = ['this','is','a','sentence']\n",
    "# a = ' '.join(sentence)\n",
    "# print([a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>as</th>\n",
       "      <th>became</th>\n",
       "      <th>by</th>\n",
       "      <th>career</th>\n",
       "      <th>claimed</th>\n",
       "      <th>do</th>\n",
       "      <th>earlier</th>\n",
       "      <th>election</th>\n",
       "      <th>elections</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>though</th>\n",
       "      <th>to</th>\n",
       "      <th>trump</th>\n",
       "      <th>vladimir</th>\n",
       "      <th>was</th>\n",
       "      <th>who</th>\n",
       "      <th>winning</th>\n",
       "      <th>witchhunt</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>doc_trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_election</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_putin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              after  as  became  by  career  claimed  do  earlier  election  \\\n",
       "doc_trump         1   0       1   0       0        0   0        0         1   \n",
       "doc_election      0   0       0   1       0        1   1        0         2   \n",
       "doc_putin         0   1       1   0       1        0   0        1         0   \n",
       "\n",
       "              elections  ...  the  though  to  trump  vladimir  was  who  \\\n",
       "doc_trump             0  ...    2       1   0      2         0    0    0   \n",
       "doc_election          0  ...    2       0   1      1         0    1    1   \n",
       "doc_putin             1  ...    1       0   0      0         1    0    0   \n",
       "\n",
       "              winning  witchhunt  with  \n",
       "doc_trump           1          0     1  \n",
       "doc_election        0          1     1  \n",
       "doc_putin           0          0     0  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentss = [doc_trump, doc_election, doc_putin]\n",
    "\n",
    "\n",
    "\n",
    "sparse_matrix = count_vectorizer.fit_transform(documentss)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "              columns=count_vectorizer.get_feature_names(), \n",
    "              index=['doc_trump', 'doc_election', 'doc_putin'])\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caption 1', 'Caption 2', 'Caption 3', 'Caption 4', 'Caption 5', 'Caption 6', 'Caption 7', 'Caption 8', 'Caption 9', 'Caption 10', 'Caption 11', 'Caption 12', 'Caption 13', 'Caption 14', 'Caption 15', 'Caption 16', 'Caption 17', 'Caption 18', 'Caption 19', 'Caption 20', 'Caption 21', 'Caption 22', 'Caption 23', 'Caption 24', 'Caption 25', 'Caption 26', 'Caption 27', 'Caption 28', 'Caption 29', 'Caption 30', 'Caption 31', 'Caption 32', 'Caption 33', 'Caption 34', 'Caption 35', 'Caption 36', 'Caption 37', 'Caption 38', 'Caption 39', 'Caption 40', 'Caption 41', 'Caption 42', 'Caption 43', 'Caption 44', 'Caption 45', 'Caption 46', 'Caption 47', 'Caption 48', 'Caption 49', 'Caption 50', 'Caption 51', 'Caption 52', 'Caption 53', 'Caption 54', 'Caption 55', 'Caption 56', 'Caption 57', 'Caption 58', 'Caption 59', 'Caption 60', 'Caption 61', 'Caption 62', 'Caption 63', 'Caption 64', 'Caption 65', 'Caption 66', 'Caption 67', 'Caption 68', 'Caption 69', 'Caption 70', 'Caption 71', 'Caption 72', 'Caption 73', 'Caption 74', 'Caption 75', 'Caption 76', 'Caption 77', 'Caption 78', 'Caption 79', 'Caption 80', 'Caption 81', 'Caption 82', 'Caption 83', 'Caption 84', 'Caption 85', 'Caption 86', 'Caption 87', 'Caption 88', 'Caption 89', 'Caption 90', 'Caption 91', 'Caption 92', 'Caption 93', 'Caption 94', 'Caption 95', 'Caption 96', 'Caption 97', 'Caption 98', 'Caption 99', 'Caption 100']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "numbers = []\n",
    "while count < 100:\n",
    "    count += 1\n",
    "    numbers.append(\"Caption {}\".format(len(numbers) + 1))\n",
    "\n",
    "a = [x for x in numbers]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
